---
title: "Hands-on Exercise 5b: Local Measures of Spatial Autocorrelation"
title-block-banner: true
date: "16-Aug-24"
date-modified: "last-modified"
toc: true
toc-depth: 4
editor: visual
execute: 
  freeze: true #never re-render during project render
  echo: true #if false, displays charts without codes
  eval: true #if false, displays codes without charts
  warning: false #dont display if there are any warnings
format: 
  html:
    code-fold: false
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: false
---

![](images/placeholder_5b.PNG){fig-align="center"}

# 1 Overview

Local Measures of Spatial Autocorrelation (LMSA) focuses on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. 

The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. 

An example is Local Indicators of Spatial Association (LISA). Beside LISA, Getis-Ord’s Gi-statistics will be introduce as an alternative LISA statistics that present complementary information or allow us to obtain similar insights for geographically referenced data.

This is an extension of Hands-on Exercise 5a, parts 1 to 4.2 follows the previous exercise.


::: {.sherbox .sherlock data-latex="sherlock"}
**The Analytical Question**

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is ***No***, then, our next question will be "is there sign of spatial clustering?" And, if the answer for this question is ***Yes***, then our next question will be "where are these clusters?"

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.
:::

# 2 The Packages

::: panel-tabset
## Packages

+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| Package                                                                                                                                      | Description                                                                                                                               |
+==============================================================================================================================================+===========================================================================================================================================+
| [**spdep**](https://cran.r-project.org/web/packages/spdep/index.html)                                                                        | To compute spatial weights, Global and Local Spatial Autocorrelation statistics (eg plot Moran scatterplot, compute and plot correlogram) |
+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| [**sf**](https://cran.r-project.org/web/packages/sf/index.html)                                                                              | For importing, managing, and processing geospatial data                                                                                   |
+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| [**tidyverse**](https://www.tidyverse.org/)                                                                                                  | A collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data.               |
+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| [**tmap**](https://cran.r-project.org/web/packages/tmap/)                                                                                    | To prepare cartographic quality choropleth map                                                                                            |
+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+
| [**DT**](https://rstudio.github.io/DT/), [**knitr**](https://yihui.org/knitr/) and [**kableExtra**](https://haozhu233.github.io/kableExtra/) | For building tables                                                                                                                       |
+----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+

: {tbl-colwidths="\[15,85\]"}

## Code

```{r}
pacman::p_load(sf, spdep, 
               tmap, 
               tidyverse, 
               DT, knitr, kableExtra)

# -   Creates a package list containing the necessary R packages
# -   Checks if the R packages in the package list have been installed
# -   If not installed, will installed the missing packages & launch into R environment.
```
:::

# 3 The Data

Two data sets will be used in this hands-on exercise, they are:

+------------+--------------+--------------------------------------------------------------------+
| Type       | Name         | Details                                                            |
+============+==============+====================================================================+
| Geospatial | *Hunan*      | -   County boundary layer                                          |
|            |              |                                                                    |
|            |              | -   Format: SHP (ESRI Shapefile)                                   |
+------------+--------------+--------------------------------------------------------------------+
| Aspatial   | *Hunan_2012* | -   Contains selected Hunan's local development indicators in 2012 |
|            |              |                                                                    |
|            |              | -   Format: CSV                                                    |
+------------+--------------+--------------------------------------------------------------------+

: {tbl-colwidths="\[20,20,60\]"}

## 3.1 Loading the Data

In this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

::: panel-tabset
## Import shapefile

The code chunk below uses [`st_read()`](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import *Hunan* shapefile into R.

```{r}
#output: simple features object

hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

```{r}
#| echo: false
# Setting theme

hunan %>% 
  kable() %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                            fixed_thead = T)
```

## Import csv file

Next, we will import *Hunan_2012.csv* into R by using `read_csv()` of **readr** package.

```{r}
#output: R dataframe class

hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

```{r}
#| echo: false

hunan2012 %>% 
  kable() %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                            fixed_thead = T)
```

## Performing relational join

The code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using `left_join()` of **dplyr** package.

```{r}
colnames(hunan)
```

```{r}
colnames(hunan2012)
```

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```
:::

## 3.2 Visualising Regional Development Indicator

Now, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using *qtm()* of **tmap** package.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", 
          size=0.3) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F)

gdppc <- qtm(hunan, "GDPPC") +
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 0.9,
            legend.text.size = 0.5)

tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# 4 Local Indicatros of Spatial Association

-   Local Indicators of Spatial Association (LISA): statistics that evaluate the existence of clusters in the spatial arrangement of a given variable.

-   Eg if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, we learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran's I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## 4.1 Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

-   `poly2nb()` of **spdep** package to compute contiguity weight matrices for the study area.
-   This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a "queen" argument that takes TRUE or FALSE as options.
-   Default: *Queen = TRUE*, but if you change it to *FALSE*, you are using ROOK method.
-   The output that you will get is a **list**.

The code chunk below will be used to compute Queen contiguity weight matrix:

```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```

::: {.lightbox .light data-latex="light"}
**Interpretation**

-   There are 88 area units in Hunan.
-   Most connected area unit has 11 neighbours.
-   There are 2 area units with only 1 neighbour.
:::

## 4.2 Row-standardised weights matrix

-   Assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (*style="W"*).

-   This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values.

-   While this is the most intuitive way to summaries the neighbors' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.

-   *Style="W"* option used for this example for simplicity's sake but more robust options are available, notably *style="B"*.

    -   Styles:
        -   W: row standardised (sums over all links to n)
        -   B: basic binary coding
        -   C: globally standardised (sums over all links to n)
        -   U: equal to C divided by the number of neighbours (sums over all links to unity)
        -   S: variance-stabilizing coding scheme (sums over all links to n)
        -   minmax: divides the weights by min of the max row sums and max column sums of the input weights; similar to C/U

-   The input of `*nb2listw()` must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.

```{r}
rswm_q <- nb2listw(wm_q,
                   style="W",
                   zero.policy = TRUE) 
rswm_q
```

*zero.policy = TRUE* allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a *zero.policy = FALSE* would return an error.

If *zero policy = TRUE*, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length = length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

## 4.3 Computing Local Moran's I

[`localmoran()`](https://r-spatial.github.io/spdep/reference/localmoran.html) function of **spdep** computes $I_i$ values, given a set of $z_i$ values and a listw object providing neighbour weighting information for the polygon associated with the zi values

The code chunks below are used to compute local Moran's I of *GDPPC2012* at the county level.

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)

head(localMI,10) %>% 
  kable() %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                            fixed_thead = T)


```

-   Ii: the local Moran's I statistics
-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis
-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis
-   Z.Ii:the standard deviate of local moran statistic
-   Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using [`printCoefmat()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/printCoefmat).

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```


### 4.3.1 Mapping the Local Moran's I

-   Before mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame.
-   The output SpatialPolygonDataFrame is called *hunan.localMI*
-   The code chunks below can be used to perform the task. 

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)

hunan.localMI
```

### 4.3.2 Mapping local Moran's I values

Plot the local Moran's I values by using choropleth mapping functions of **tmap** package.

```{r fig.width=12, fig.height=8}
#| code-fold: true
#| code-summary: "Show the code"

tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F)

```

### 4.3.3 Mapping Local Moran's I p-values

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.


```{r fig.width=12, fig.height=8}
#| code-fold: true
#| code-summary: "Show the code"
#| 
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

## Mapping both Local Moran's I values and p-values

Plot both the local Moran's I values map and its corresponding p-values map next to each other for easier comparison.

```{r fig.width=12, fig.height=8}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", #<<
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)+
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 0.9,
            legend.text.size = 0.8)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", #<<
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 0.9,
            legend.text.size = 0.8)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

- You need to plot it together to draw any conclusions 
- Then we need to decompose these relationshops using LISA Cluster

# 5 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

## 5.1 Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using [`moran.plot()`](https://r-spatial.github.io/spdep/reference/moran.plot.html) of **spdep**.

```{r fig.width=12, fig.height=8}
par(bg = '#E4D5C9')

nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County),
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

::: {.lightbox .light data-latex="light"}

**Interpretation**

-   Plot is split in **4 quadrants**.
    -   LH (Neg- ac, Outlier), HH (Pos+ ac, Cluster)
    -   LL (Pos+ ac, Cluster), HL (Neg- ac, Outlier)
    -   Wz is neighbour (y axis), z is you/target (x axis)
-   For this plot, you need to standardise it by scaling it and have both to cutoff at 0. 
-   The top right corner belongs to areas that have **high GDPPC** and are surrounded by other areas that have the average level of GDPPC. 
    -   This are the **high-high locations** in the lesson slide: "I'm high and my neighbours are high."
 
:::

## 5.2 Plotting Moran scatterplot with standardised variable

-   Use `scale()` to centers and scales the variable.
-   Here, centering is done by **subtracting the mean** (omitting NAs) the corresponding columns, 
-   and scaling is done by dividing the (centered) variable by their standard deviations.
-   The `as.vector()` added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

Plot the Moran scatterplot again by using the code chunk below.

```{r fig.width=6, fig.height=6}
par(bg = '#E4D5C9')

nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

::: {.lightbox .light data-latex="light"}

**Interpretation**

-   Plot is split in **4 quadrants**.
    -   LH (Neg- ac, Outlier), HH (Pos+ ac, cluster)
    -   LL (Pos+ ac, Cluster), HL (Neg- ac, outlier)
    -   Wz is neighbour (y axis), z is you/target (x axis)
-   After scaling it, we can see that both is now cutoff at 0.
 
:::

## 5.3 Preparing LISA map classes


### 5.3.1 Convert to Vector

The code chunks below show the steps to prepare a LISA cluster map.

```{r}
quadrant <- vector(mode="numeric",
                   length=nrow(localMI))
```

### 5.3.2 Derive spatially lagged GDPPC

Next, derive the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.

```{r}
hunan$lag_GDPPC <- lag.listw(rswm_q, 
                             hunan$GDPPC)

DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
```

### 5.3.3 Center variable around mean

This is follow by centering the local Moran's around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

### 5.3.4 Set alpha value

Next, we will set a statistical significance level for the local Moran.

```{r}
signif <- 0.05       
```

### 5.3.5 Define quadrants

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
#| eval: false
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

### 5.3.6 Place Moran

Lastly, place non-significant Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```


## 5.4 Plotting LISA map


### 5.4.1 LISA Map

Now, we can build the LISA map by using the code chunks below.

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#eeeae2", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F)

```

::: {.notebox .note data-latex="note"}

**Quadrants**

-   High-High (Cluster): counties that have High GDPPC surrounded by counties with High GDPPC
-   High-Low (Outlier): counties that have High GDPPC surrounded by counties with Low GDPPC
-   Low-High (Outlier): counties that have low GDPPC surrounded by counties with High GDPPC
-   Low-Low (Cluster): counties that have low GDPPC surrounded by counties with low GDPPC

:::

### 5.4.2 Local Moran's I and p-values

Plot both the local Moran's I values map and its corresponding p-values map next to each other for easier comparison.

The code chunk below will be used to create such visualisation.

```{r fig.width=12, fig.height=8}
gdppc <- qtm(hunan, "GDPPC") +
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

hunan.localMI$quadrant <- quadrant
colors <- c("#eeeae2", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```

::: {.lightbox .light data-latex="light"}
**Question: What statistical observations can you draw from the LISA map above?**

-   We should look at the original value to make sense of the previous map.
-   Focusing on the Low-High, the original map does not show any high values. 
-   HighHigh cluster is definitely correct. 
-   But the low-low cluster should be a Low-high outlier.
:::

We can also include the local Moran's I map and p-value map as shown below for easy comparison.

```{r fig.width=12, fig.height=8}

tmap_arrange(localMI.map, pvalue.map, 
             asp=1, ncol=2)
```


# 6 Hot Spot and Cold Spot Area Analysis

Besides detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

## 6.1 Getis and Ord's G-Statistics

**NOTE: If you have negative values, you cannot use Getis and Ord's G Stats. It must be all positive. Must calculated the distance based matrix and not contiguity matrix.**

-   Used to to detect spatial anomalies is the Getis and Ord's G-statistics .

-   Looks at neighbours within a defined proximity to identify where either high or low values clutser spatially.

-   Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

1.  Deriving spatial weight matrix
2.  Computing Gi statistics
3.  Mapping Gi statistics

### 6.1.1 Deriving distance-based weight matrix

First, we need to define a new set of neighbours. While the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.

There are two type of distance-based proximity matrix, they are:

-   fixed distance weight matrix; and
-   adaptive distance weight matrix.

#### 6.1.1.1 Deriving the centroid

-   We will need points to associate with each polygon before we can make our connectivity graph.
-   It will be a little more complicated than just running `st_centroid()` on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. 
-   Use mapping function: applies a given function to each element of a vector and returns a vector of the same length. The input vector is geometry column of us.bound. The function will be `st_centroid()`. We will be using map_dbl variation of map from the purrr package. 

-   To get longitude values we map the `st_centroid()` function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

Do the same for latitude with one key difference: We will access the second value per each centroid with [[2]].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Use `cbind()` to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

#### 6.1.1.2 Determine the cut-off distance

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [`knearneigh()`](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.
-   Convert the knn object returned by `knearneigh()` into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [`knn2nb()`](https://r-spatial.github.io/spdep/reference/knn2nb.html).
-   Return the length of neighbour relationship edges by using [`nbdists()`](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.
-   Remove the list structure of the returned object by using [`unlist()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

Results above show that:
-   The largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.
-   We will round up to 62 to ensure that all counties will have at least 1 nearest neighbour.

#### 6.1.1.3 Computing fixed distance weight matrix

Compute the distance weight matrix by using [`dnearneigh()`](https://r-spatial.github.io/spdep/reference/dnearneigh.html) as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, `nb2listw()` is used to convert the nb object into spatial weights object. The input of `nb2listw()` must be an object of class nb. The syntax of the function has two major arguments, namely `style` and `zero.poly`.

-   style can take values “W”, “B”, “C”, “U”, “minmax” and “S”.
    -   + B is the basic binary coding
    -   + W is row standardised (sums over all links to n),
    -   + C is globally standardised (sums over all links to n),
    -   + U is equal to C divided by the number of neighbours (sums over all links to unity)
    -   + S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

The output spatial weights object is called `wm62_lw`.

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

#### 6.1.1.4 Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

In the example below, we fix the number of neighbours to 8.

```{r}
knn <- knn2nb(knearneigh(coords, 
                         k=8)) #<<
knn
```

Next, `nb2listw()` is used to convert the nb object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

### 6.1.2 Computing Gi statistics


#### 6.1.2.1 Gi statistics using fixed distance

```{r echo=TRUE, eval=TRUE}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

Results above show that:

-   The output of `localG()` is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.
-   The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

-   Join the Gi values to their corresponding hunan sf data frame by using the code chunk below.
-   The 3 sub tasks are: 
    -   Convert the output vector (i.e. gi.fixed) into r matrix object by using `as.matrix().c`
    -   `cbind()` is used to join hunan data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. 
    Field name of the gi values is renamed to gstat_fixed by using `names()`.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)

hunan.gi
```

#### 6.1.2.2 Mapping Gi values with fixed distance weights

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r fig.width=12, fig.height=8}

gdppc <- qtm(hunan, "GDPPC") +
    tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5) +
    tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

::: {.lightbox .light data-latex="light"}

**Question: What statistical observation can you draw from the Gi map above?**

-   In the left side, western region is the cold spot area while the hot spot area is in the east side. 
-   If you plot the transportation line, you can see that it is mainly on the east side. So this might be one of the underlying reason why the hot spot areas are on the right side.

:::


#### 6.1.2.3 Gi statistics using adaptive distance

The code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e *knb_lw*).

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

#### 6.1.2.4 Mapping Gi values with adaptive distance weights

We can also visualise the locations of hot spot and cold spot areas.

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r fig.width=12, fig.height=8}

gdppc<- qtm(hunan, "GDPPC")+
      tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

Gimap2 <- tm_shape(hunan.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5) +
  tm_layout(bg.color = "#E4D5C9",
            frame = F,
            legend.title.size = 1.2,
            legend.text.size = 1)

tmap_arrange(gdppc, 
             Gimap2, 
             asp=1, 
             ncol=2)
```

::: {.lightbox .light data-latex="light"}

**Question: What statistical observation can you draw from the Gi map above?**

-   This plot with the adaptive weights is actually smoother than the previous map with fixed weights
-   The range in the legend has also changed
:::

# 6 Reference

Kam, T. S. Lobal Measures of Spatial Autocorrelation. *R for Geospatial Data Science and Analytics.* <https://r4gdsa.netlify.app/chap10.html>